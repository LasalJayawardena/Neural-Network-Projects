{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Simple Neural Network with PyTorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Visualizing MNIST Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5),(0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST('MNIST_data/', download=False, train = True, transform= transform)\n",
    "\n",
    "testset = datasets.MNIST('MNIST_data/', download=False, train = False, transform= transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set : 60000\n"
     ]
    }
   ],
   "source": [
    "print(f'Size of train set : {len(trainset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test set : 10000\n"
     ]
    }
   ],
   "source": [
    "print(f'Size of test set : {len(testset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 7\n",
    "image, label = trainset[idx]\n",
    "plt.imshow(image.numpy().squeeze(), cmap='gray');\n",
    "plt.title(label);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Dataset and Setting DataLoader Into Train,Test and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = 0.2\n",
    "num_train = len(trainset)\n",
    "split = int(np.floor(valid_size*num_train))\n",
    "\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "train_idx, valid_idx = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=64, sampler= train_sampler)\n",
    "\n",
    "validloader = DataLoader(trainset, batch_size=64, sampler= valid_sampler)\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches in train loader : 750 \n",
      "Batches in valid loader : 188 \n",
      "Batches in test loader : 157 \n"
     ]
    }
   ],
   "source": [
    "print(f\"Batches in train loader : {len(trainloader)} \")\n",
    "print(f\"Batches in valid loader : {len(validloader)} \")\n",
    "print(f\"Batches in test loader : {len(testloader)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Examples in train loader : 48000 \n",
      "Total Examples in valid loader : 12000 \n",
      "Total Examples in test loader : 10000 \n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Examples in train loader : {len(trainloader.sampler)} \")\n",
    "print(f\"Total Examples in valid loader : {len(validloader.sampler)} \")\n",
    "print(f\"Total Examples in test loader : {len(testloader.dataset)} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Neural Network or Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Classifier,self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(784,256)\n",
    "        self.linear2 = nn.Linear(256,128)\n",
    "        self.linear3 = nn.Linear(128,10)\n",
    "        #droput layer to prevent overfitiing\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, images):\n",
    "        # convert images into input feature dimension\n",
    "        # [64,1,28,28] -> [64, 784]\n",
    "        images = images.view(images.shape[0], -1)\n",
    "\n",
    "        # First layer\n",
    "        z1 = self.linear1(images)\n",
    "        a1 = self.dropout(F.relu(z1))\n",
    "\n",
    "        # Second Layer\n",
    "        z2 = self.linear2(a1)\n",
    "        a2 = self.dropout(F.relu(z2))\n",
    "\n",
    "        # Third layer\n",
    "        z3 = self.linear3(a2)\n",
    "        a3 = F.log_softmax(z3, dim=1)\n",
    "\n",
    "        return a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (linear1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (linear3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 256]         200,960\n",
      "           Dropout-2                  [-1, 256]               0\n",
      "            Linear-3                  [-1, 128]          32,896\n",
      "           Dropout-4                  [-1, 128]               0\n",
      "            Linear-5                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.90\n",
      "Estimated Total Size (MB): 0.91\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(1,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traing the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from utils import multiclass_accuracy, view_classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.003)\n",
    "epochs = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "Train Loss : 0.3878607063293457\n",
      "Valid Loss : 0.20256620673264594 \n",
      "Valid Accuracy : 0.9399933218955994\n",
      "Epoch : 1\n",
      "Train Loss : 0.35730376101533573\n",
      "Valid Loss : 0.20836124904057446 \n",
      "Valid Accuracy : 0.9385804533958435\n",
      "Epoch : 2\n",
      "Train Loss : 0.3486757804254691\n",
      "Valid Loss : 0.19271373271228784 \n",
      "Valid Accuracy : 0.9429853558540344\n",
      "Epoch : 3\n",
      "Train Loss : 0.3363995847205321\n",
      "Valid Loss : 0.20209047152720233 \n",
      "Valid Accuracy : 0.9377493262290955\n",
      "Epoch : 4\n",
      "Train Loss : 0.32943732173244156\n",
      "Valid Loss : 0.2042334534703417 \n",
      "Valid Accuracy : 0.9402427077293396\n",
      "Epoch : 5\n",
      "Train Loss : 0.3279194603860378\n",
      "Valid Loss : 0.17397375760520709 \n",
      "Valid Accuracy : 0.9477227330207825\n",
      "Epoch : 6\n",
      "Train Loss : 0.3156129492421945\n",
      "Valid Loss : 0.18768895611642522 \n",
      "Valid Accuracy : 0.9445645213127136\n",
      "Epoch : 7\n",
      "Train Loss : 0.3221787653664748\n",
      "Valid Loss : 0.17417927968137442 \n",
      "Valid Accuracy : 0.9493849873542786\n",
      "Epoch : 8\n",
      "Train Loss : 0.3039060103148222\n",
      "Valid Loss : 0.18344999567427217 \n",
      "Valid Accuracy : 0.944896936416626\n",
      "Epoch : 9\n",
      "Train Loss : 0.30473986434936523\n",
      "Valid Loss : 0.17431296600385549 \n",
      "Valid Accuracy : 0.9490525126457214\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    valid_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        log_p_s  = model.forward(images)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(log_p_s, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    for images, labels in validloader:\n",
    "        \n",
    "        log_p_s = model.forward(images)\n",
    "        ps = torch.exp(log_p_s)\n",
    "        \n",
    "        loss= criterion(log_p_s, labels)\n",
    "        \n",
    "        valid_acc += multiclass_accuracy(ps, labels)\n",
    "        valid_loss+= loss.item()\n",
    "    \n",
    "    \n",
    "    train_loss = train_loss/len(trainloader)\n",
    "    valid_loss = valid_loss/len(validloader)\n",
    "    valid_acc = valid_acc/len(validloader)\n",
    "    \n",
    "    \n",
    "    print(f\"Epoch : {e}\\nTrain Loss : {train_loss}\\nValid Loss : {valid_loss} \\nValid Accuracy : {valid_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : 0.16245626340246505 \n",
      "Test Accuracy : 0.9546178579330444\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "test_acc = 0\n",
    "\n",
    "for images, labels in testloader:\n",
    "\n",
    "    log_p_s = model.forward(images)\n",
    "    ps = torch.exp(log_p_s)\n",
    "\n",
    "    loss= criterion(log_p_s, labels)\n",
    "\n",
    "    test_acc += multiclass_accuracy(ps, labels)\n",
    "    test_loss+= loss.item()\n",
    "    \n",
    "test_loss = test_loss/len(testloader)\n",
    "test_acc = test_acc/len(testloader)\n",
    "\n",
    "print(f\"Test Loss : {test_loss} \\nTest Accuracy : {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images.labels = dataiter.next()\n",
    "\n",
    "\n",
    "idx = 8\n",
    "logps  = model.forward(images[idx])\n",
    "ps = torch.exp(logps)\n",
    "\n",
    "view_classify(images[idx], ps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
